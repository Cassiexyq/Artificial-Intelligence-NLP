## 新华社和非新华社的文本分类

​	--	抄袭文本的判断

#### 思路

1. 利用词向量
2. 标准化 Z-score
3. 除掉新华社字样
4. 先按原正负比例计算 pos/neg = 8393 / 78661
5. 评估： 这里我想用所有非新华社，所有新华社的各自准确率作为评估方式，也可以利用precision和recall

抄袭文本，既然要找抄袭文本，不应该去追求测试集的过分高，这样就把是抄袭文本但标签为0为了尽力区分开来，对于分类模型而言就不是那些与新华社有着共同词向量特征作为主要依据了，我们的目的应该是尽量找到更多的假阳例，这说明模型把负样本分错了的直接原因就是它非常像新华社里的某篇的原因！



#### 结果（同一数据集）

| 算法                   | 参数          | 新华社 acc | 非新华社acc | 运行时间 |
| ---------------------- | ------------- | ---------- | ----------- | -------- |
| 逻辑回归               | balanced      | 0.932      | 0.918       | 特快     |
| 逻辑回归CV（auc=0.98） | cv=5,balanced | 0.932      | 0.918       | 特快     |
| KNN （Z-score）        | k=1,distance  | 0.996      | 0.844       | 非常慢   |
| KNN (min-max)          | k=1,distance  | 0.996      | 0.846       | 非常慢   |
| KNN(Z-SCORE)           | k=2,distance  | 0.996      | 0.844       | 非常慢   |
| SVM(SVC)               |               |            |             |          |
| SVM（SVR）             |               |            |             |          |
| 贝叶斯                 |               |            |             |          |
| 决策树                 |               |            |             |          |
| 随机森林               |               |            |             |          |

从表中可以看出，归一化或者标准化都是可以的，对于KNN的k，k=1就行了

KNN的确作为一个非常简单的分类模型却有着极高的准确度。

